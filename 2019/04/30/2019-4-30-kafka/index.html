<!DOCTYPE html>


  <html class="light page-default">


<head>
  <meta charset="utf-8">
  
  <title>kafka | Hexo</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="后端、技术、博客、架构、全栈" />
  

  <meta name="description" content="kafka网络通信模型 （1）Acceptor：1个接收线程，负责监听新的连接请求，同时注册OP_ACCEPT 事件，将新的连接按照“round robin”方式交给对应的 Processor 线程处理； （2）Processor：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://yoursite.com/2019/04/30/2019-4-30-kafka/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="kafka网络通信模型 （1）Acceptor：1个接收线程，负责监听新的连接请求，同时注册OP_ACCEPT 事件，将新的连接按照“round robin”方式交给对应的 Processor 线程处理； （2）Processor：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191204220047825.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108092730192.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211105451796.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211105517601.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108151921837.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108152125545.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191107221809350.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191107223940194.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191212095641531.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191212135157447.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191213094928449.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191213094951652.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108114145781.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211114800350.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191210174046139.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191210181215208.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211093647072.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191025140100157.png">
<meta property="og:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211173947135.png">
<meta property="article:published_time" content="2019-04-29T16:00:00.000Z">
<meta property="article:modified_time" content="2020-01-06T07:17:32.737Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191204220047825.png">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    
<link rel="stylesheet" href="/css/personal-style.css">

  

  

  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?65e0b4df283d78e15f8c78f238ec9593";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

<meta name="generator" content="Hexo 4.2.0"></head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">导航</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">导航</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">Posts List</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka"><span class="toc-text">kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#网络通信模型"><span class="toc-text">网络通信模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#acceptor"><span class="toc-text">acceptor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#processor"><span class="toc-text">processor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requestChannel"><span class="toc-text">requestChannel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaRequestHandler"><span class="toc-text">KafkaRequestHandler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaApis"><span class="toc-text">KafkaApis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主题"><span class="toc-text">主题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#增加主题"><span class="toc-text">增加主题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#副本"><span class="toc-text">副本</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#In-sync-Replicas（ISR）"><span class="toc-text">In-sync Replicas（ISR）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#领导者选举"><span class="toc-text">领导者选举</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#生产者"><span class="toc-text">生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#无丢失消息"><span class="toc-text">无丢失消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#消息重发"><span class="toc-text">消息重发</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#幂等"><span class="toc-text">幂等</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#事务"><span class="toc-text">事务</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#客户端生产者"><span class="toc-text">客户端生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#发送消息"><span class="toc-text">发送消息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sender线程"><span class="toc-text">sender线程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消费者"><span class="toc-text">消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消费组"><span class="toc-text">消费组</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#消费者入组"><span class="toc-text">消费者入组</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#偏移量提交"><span class="toc-text">偏移量提交</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#手动提交"><span class="toc-text">手动提交</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自动提交"><span class="toc-text">自动提交</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#重平衡"><span class="toc-text">重平衡</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#控制器"><span class="toc-text">控制器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#controller选举"><span class="toc-text">controller选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分区leader选举"><span class="toc-text">分区leader选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#控制器故障转移（Failover）"><span class="toc-text">控制器故障转移（Failover）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#处理生产者请求的逻辑如下："><span class="toc-text">处理生产者请求的逻辑如下：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#处理-Follower-副本拉取消息的逻辑如下："><span class="toc-text">处理 Follower 副本拉取消息的逻辑如下：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#从-Leader-拉取消息的处理逻辑如下："><span class="toc-text">从 Leader 拉取消息的处理逻辑如下：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#协调器"><span class="toc-text">协调器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rocketMQ"><span class="toc-text">rocketMQ</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#namesrv-VS-zk"><span class="toc-text">namesrv VS zk</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#消息存储"><span class="toc-text">消息存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-text">reference</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="default-2019-4-30-kafka" class="article article-type-default" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">kafka</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.04.30</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>John Doe</span>
        </span>
      

      


      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h2 id="网络通信模型"><a href="#网络通信模型" class="headerlink" title="网络通信模型"></a>网络通信模型</h2><p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191204220047825.png" alt="image-20191204220047825"></p>
<p>（1）<strong>Acceptor</strong>：1个接收线程，负责监听新的连接请求，同时注册OP_ACCEPT 事件，将新的连接按照<strong>“round robin”</strong>方式交给对应的 Processor 线程处理；<br> （2）<strong>Processor</strong>：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事件，N 的大小由<strong>“num.networker.threads”</strong>决定；<br> （3）<strong>KafkaRequestHandler</strong>：M个请求处理线程，包含在线程池—KafkaRequestHandlerPool内部，从RequestChannel的全局请求队列—requestQueue中获取请求数据并交给KafkaApis处理，M的大小由<strong>“num.io.threads”</strong>决定；<br> （4）<strong>RequestChannel</strong>：其为Kafka服务端的请求通道，该数据结构中包含了一个全局的请求队列 requestQueue和多个与Processor处理器相对应的响应队列responseQueue，提供给Processor与请求处理线程KafkaRequestHandler和KafkaApis交换数据的地方。<br> （5）<strong>NetworkClient</strong>：其底层是对 Java NIO 进行相应的封装，位于Kafka的网络接口层。Kafka消息生产者对象—KafkaProducer的send方法主要调用NetworkClient完成消息发送；<br> （6）<strong>SocketServer</strong>：其是一个NIO的服务，它同时启动一个Acceptor接收线程和多个Processor处理器线程。提供了一种典型的Reactor多线程模式，将接收客户端请求和处理请求相分离；<br> （7）<strong>KafkaServer</strong>：代表了一个Kafka Broker的实例；其startup方法为实例启动的入口；<br> （8）<strong>KafkaApis</strong>：Kafka的业务逻辑处理Api，负责处理不同类型的请求；比如<strong>“发送消息”</strong>、<strong>“获取消息偏移量—offset”</strong>和<strong>“处理心跳请求”</strong>等；</p>
<h3 id="acceptor"><a href="#acceptor" class="headerlink" title="acceptor"></a>acceptor</h3><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">def run() &#123;</span><br><span class="line">  <span class="comment">// 注册accept事件</span></span><br><span class="line">  serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)</span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> currentProcessorIndex = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> keys = nioSelector.selectedKeys()</span><br><span class="line">          <span class="keyword">val</span> iter = keys.iterator()</span><br><span class="line">          <span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">val</span> key = iter.next</span><br><span class="line">              iter.remove()</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> (key.isAcceptable) &#123;</span><br><span class="line">                accept(key).foreach &#123; socketChannel =&gt;</span><br><span class="line"></span><br><span class="line">                  <span class="comment">// Assign the channel to the next processor (using round-robin) to which the</span></span><br><span class="line">                  <span class="comment">// channel can be added without blocking. If newConnections queue is full on</span></span><br><span class="line">                  <span class="comment">// all processors, block until the last one is able to accept a connection.</span></span><br><span class="line">                  <span class="keyword">var</span> retriesLeft = synchronized(processors.length)</span><br><span class="line">                  <span class="keyword">var</span> processor: Processor = <span class="literal">null</span></span><br><span class="line">                  <span class="keyword">do</span> &#123;</span><br><span class="line">                    retriesLeft -= <span class="number">1</span></span><br><span class="line">                    processor = synchronized &#123;</span><br><span class="line">                      <span class="comment">// adjust the index (if necessary) and retrieve the processor atomically for</span></span><br><span class="line">                      <span class="comment">// correct behaviour in case the number of processors is reduced dynamically						</span></span><br><span class="line">                      <span class="comment">// round robin算法找到处理线程</span></span><br><span class="line">                      currentProcessorIndex = currentProcessorIndex % processors.length</span><br><span class="line">                      processors(currentProcessorIndex)</span><br><span class="line">                    &#125;</span><br><span class="line">                    currentProcessorIndex += <span class="number">1</span></span><br><span class="line">                    <span class="comment">// 处理连接</span></span><br><span class="line">                  &#125; <span class="keyword">while</span> (!assignNewConnection(socketChannel, processor, retriesLeft == <span class="number">0</span>))</span><br><span class="line">                &#125;</span><br><span class="line">              &#125; <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">throw</span> new IllegalStateException(<span class="string">"Unrecognized key state for acceptor thread."</span>)</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              case e: Throwable =&gt; error(<span class="string">"Error while accepting connection"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// We catch all the throwables to prevent the acceptor thread from exiting on exceptions due</span></span><br><span class="line">        <span class="comment">// to a select operation on a specific channel or a bad request. We don't want</span></span><br><span class="line">        <span class="comment">// the broker to stop responding to requests from other clients in these scenarios.</span></span><br><span class="line">        case e: ControlThrowable =&gt; <span class="keyword">throw</span> e</span><br><span class="line">        case e: Throwable =&gt; error(<span class="string">"Error occurred"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    debug(<span class="string">"Closing server socket and selector."</span>)</span><br><span class="line">    CoreUtils.swallow(serverChannel.close(), <span class="keyword">this</span>, Level.ERROR)</span><br><span class="line">    CoreUtils.swallow(nioSelector.close(), <span class="keyword">this</span>, Level.ERROR)</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> def assignNewConnection(socketChannel: SocketChannel, processor: Processor, mayBlock: <span class="built_in">Boolean</span>): <span class="built_in">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (processor.accept(socketChannel, mayBlock, blockedPercentMeter)) &#123;</span><br><span class="line">    debug(s<span class="string">"Accepted connection from <span class="subst">$&#123;socketChannel.socket.getRemoteSocketAddress&#125;</span> on"</span> +</span><br><span class="line">      s<span class="string">" <span class="subst">$&#123;socketChannel.socket.getLocalSocketAddress&#125;</span> and assigned it to processor <span class="subst">$&#123;processor.id&#125;</span>,"</span> +</span><br><span class="line">      s<span class="string">" sendBufferSize [actual|requested]: [<span class="subst">$&#123;socketChannel.socket.getSendBufferSize&#125;</span>|<span class="variable">$sendBufferSize</span>]"</span> +</span><br><span class="line">      s<span class="string">" recvBufferSize [actual|requested]: [<span class="subst">$&#123;socketChannel.socket.getReceiveBufferSize&#125;</span>|<span class="variable">$recvBufferSize</span>]"</span>)</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125; <span class="keyword">else</span></span><br><span class="line">    <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="processor"><a href="#processor" class="headerlink" title="processor"></a>processor</h3><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> newConnections = new ArrayBlockingQueue[SocketChannel](connectionQueueSize)</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> inflightResponses = mutable.Map[String, RequestChannel.Response]()</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> responseQueue = new LinkedBlockingDeque[RequestChannel.Response]()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	def accept(socketChannel: SocketChannel,</span><br><span class="line">             mayBlock: <span class="built_in">Boolean</span>,</span><br><span class="line">             acceptorIdlePercentMeter: com.yammer.metrics.core.Meter): <span class="built_in">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> accepted = &#123;</span><br><span class="line">      <span class="comment">// 加入队列newConnection，队列属于ArrayBlockingQueue</span></span><br><span class="line">      <span class="keyword">if</span> (newConnections.offer(socketChannel))</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (mayBlock) &#123;</span><br><span class="line">        <span class="keyword">val</span> startNs = time.nanoseconds</span><br><span class="line">        newConnections.put(socketChannel)</span><br><span class="line">        acceptorIdlePercentMeter.mark(time.nanoseconds() - startNs)</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">      &#125; <span class="keyword">else</span></span><br><span class="line">        <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (accepted)</span><br><span class="line">    <span class="comment">// 马上唤醒selector.pool()，继续从newConnections里拿新连接</span></span><br><span class="line">      wakeup()</span><br><span class="line">    accepted</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="keyword">override</span> def run() &#123;</span><br><span class="line">    startupComplete()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// setup any new connections that have been queued up</span></span><br><span class="line">          <span class="comment">//  newConnections.poll()，从队列中拿到连接成功的socket，并注册到nio selector</span></span><br><span class="line">          configureNewConnections()</span><br><span class="line">          <span class="comment">// register any new responses for writing</span></span><br><span class="line">          <span class="comment">// 处理响应队列responseQueue里的响应，注册OP_WRITE到nio selector</span></span><br><span class="line">          processNewResponses()</span><br><span class="line">          <span class="comment">// selector.poll()监听事件</span></span><br><span class="line">          poll()</span><br><span class="line">          <span class="comment">// read事件被触发；selector.completedReceives.asScala.foreach；将请求Request添加至requestChannel的全局请求队列—requestQueue中，等待KafkaRequestHandler来处理</span></span><br><span class="line">          processCompletedReceives()</span><br><span class="line">          <span class="comment">// write事件被触发；selector.completedSends.asScala.foreach，将response发送给客户端，则将其从inflightResponses移除，同时通过调用“selector.unmute”方法为对应的连接通道重新注册OP_READ事件</span></span><br><span class="line">          processCompletedSends()</span><br><span class="line">          <span class="comment">// 断开事件被触发；处理断开连接的队列；selector.disconnected.keySet.asScala.foreach；将该response从inflightResponses集合中移除，同时将connectionQuotas统计计数减1</span></span><br><span class="line">          processDisconnected()</span><br><span class="line">          closeExcessConnections()</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="comment">// We catch all the throwables here to prevent the processor thread from exiting. We do this because</span></span><br><span class="line">          <span class="comment">// letting a processor exit might cause a bigger impact on the broker. This behavior might need to be</span></span><br><span class="line">          <span class="comment">// reviewed if we see an exception that needs the entire broker to stop. Usually the exceptions thrown would</span></span><br><span class="line">          <span class="comment">// be either associated with a specific socket channel or a bad request. These exceptions are caught and</span></span><br><span class="line">          <span class="comment">// processed by the individual methods above which close the failing channel and continue processing other</span></span><br><span class="line">          <span class="comment">// channels. So this catch block should only ever see ControlThrowables.</span></span><br><span class="line">          case e: Throwable =&gt; processException(<span class="string">"Processor got uncaught exception."</span>, e)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      debug(s<span class="string">"Closing selector - processor <span class="variable">$id</span>"</span>)</span><br><span class="line">      CoreUtils.swallow(closeAll(), <span class="keyword">this</span>, Level.ERROR)</span><br><span class="line">      shutdownComplete()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// `protected` for test usage</span></span><br><span class="line">  <span class="keyword">protected</span>[network] def sendResponse(response: RequestChannel.Response, responseSend: Send) &#123;</span><br><span class="line">    <span class="keyword">val</span> connectionId = response.request.context.connectionId</span><br><span class="line">    trace(s<span class="string">"Socket server received response to send to <span class="variable">$connectionId</span>, registering for write and sending data: <span class="variable">$response</span>"</span>)</span><br><span class="line">    <span class="comment">// `channel` can be None if the connection was closed remotely or if selector closed it for being idle for too long</span></span><br><span class="line">    <span class="keyword">if</span> (channel(connectionId).isEmpty) &#123;</span><br><span class="line">      warn(s<span class="string">"Attempting to send response via channel for which there is no open connection, connection id <span class="variable">$connectionId</span>"</span>)</span><br><span class="line">      response.request.updateRequestMetrics(<span class="number">0L</span>, response)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Invoke send for closingChannel as well so that the send is failed and the channel closed properly and</span></span><br><span class="line">    <span class="comment">// removed from the Selector after discarding any pending staged receives.</span></span><br><span class="line">    <span class="comment">// `openOrClosingChannel` can be None if the selector closed the connection because it was idle for too long</span></span><br><span class="line">    <span class="keyword">if</span> (openOrClosingChannel(connectionId).isDefined) &#123;</span><br><span class="line">      <span class="comment">// 通过“selector.send”注册OP_WRITE事件</span></span><br><span class="line">      selector.send(responseSend)</span><br><span class="line">      <span class="comment">// 将该Response从responseQueue响应队列中移至inflightResponses集合中</span></span><br><span class="line">      inflightResponses += (connectionId -&gt; response)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h3 id="requestChannel"><a href="#requestChannel" class="headerlink" title="requestChannel"></a>requestChannel</h3><p>RequestChannel为Processor处理器线程与KafkaRequestHandler线程之间的数据交换提供了一个数据缓冲区，</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RequestChannel</span></span>(<span class="keyword">val</span> queueSize: <span class="built_in">Int</span>, <span class="keyword">val</span> metricNamePrefix : String) extends KafkaMetricsGroup &#123;</span><br><span class="line">  <span class="keyword">import</span> RequestChannel._</span><br><span class="line">  <span class="keyword">val</span> metrics = new RequestChannel.Metrics</span><br><span class="line">  <span class="comment">// 请求队列</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestQueue = new ArrayBlockingQueue[BaseRequest](queueSize)</span><br><span class="line">  <span class="comment">// 线程组</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> processors = new ConcurrentHashMap[<span class="built_in">Int</span>, Processor]()</span><br><span class="line">  <span class="keyword">val</span> requestQueueSizeMetricName = metricNamePrefix.concat(RequestQueueSizeMetric)</span><br><span class="line">  <span class="keyword">val</span> responseQueueSizeMetricName = metricNamePrefix.concat(ResponseQueueSizeMetric)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="KafkaRequestHandler"><a href="#KafkaRequestHandler" class="headerlink" title="KafkaRequestHandler"></a>KafkaRequestHandler</h3><p>KafkaRequestHandler也是一种线程类，在KafkaServer实例启动时候会实例化一个线程池—KafkaRequestHandlerPool对象（包含了若干个KafkaRequestHandler线程），这些线程以守护线程的方式在后台运行。在KafkaRequestHandler的run方法中会循环地从RequestChannel中阻塞式读取request，读取后再交由KafkaApis来具体处理。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">def run() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">    <span class="comment">// We use a single meter for aggregate idle percentage for the thread pool.</span></span><br><span class="line">    <span class="comment">// Since meter is calculated as total_recorded_value / time_window and</span></span><br><span class="line">    <span class="comment">// time_window is independent of the number of threads, each recorded idle</span></span><br><span class="line">    <span class="comment">// time should be discounted by # threads.</span></span><br><span class="line">    <span class="keyword">val</span> startSelectTime = time.nanoseconds</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 有300毫秒超时时间</span></span><br><span class="line">    <span class="keyword">val</span> req = requestChannel.receiveRequest(<span class="number">300</span>)</span><br><span class="line">    <span class="keyword">val</span> endTime = time.nanoseconds</span><br><span class="line">    <span class="keyword">val</span> idleTime = endTime - startSelectTime</span><br><span class="line">    aggregateIdleMeter.mark(idleTime / totalHandlerThreads.<span class="keyword">get</span>)</span><br><span class="line"></span><br><span class="line">    req match &#123;</span><br><span class="line">      case RequestChannel.ShutdownRequest =&gt;</span><br><span class="line">        debug(s<span class="string">"Kafka request handler <span class="variable">$id</span> on broker <span class="variable">$brokerId</span> received shut down command"</span>)</span><br><span class="line">        shutdownComplete.countDown()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">      case request: RequestChannel.Request =&gt;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          request.requestDequeueTimeNanos = endTime</span><br><span class="line">          trace(s<span class="string">"Kafka request handler <span class="variable">$id</span> on broker <span class="variable">$brokerId</span> handling request <span class="variable">$request</span>"</span>)</span><br><span class="line">          <span class="comment">// 正常io请求，让apis处理</span></span><br><span class="line">          apis.handle(request)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          case e: FatalExitError =&gt;</span><br><span class="line">            shutdownComplete.countDown()</span><br><span class="line">            Exit.exit(e.statusCode)</span><br><span class="line">          case e: Throwable =&gt; error(<span class="string">"Exception when handling request"</span>, e)</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          request.releaseBuffer()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      case <span class="literal">null</span> =&gt; <span class="comment">// continue</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  shutdownComplete.countDown()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandlerPool</span></span>(<span class="keyword">val</span> brokerId: <span class="built_in">Int</span>,</span><br><span class="line">                              <span class="keyword">val</span> requestChannel: RequestChannel,</span><br><span class="line">                              <span class="keyword">val</span> apis: KafkaApis,</span><br><span class="line">                              time: Time,</span><br><span class="line">                              numThreads: <span class="built_in">Int</span>,</span><br><span class="line">                              requestHandlerAvgIdleMetricName: String,</span><br><span class="line">                              logAndThreadNamePrefix : String) extends Logging with KafkaMetricsGroup &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> threadPoolSize: AtomicInteger = new AtomicInteger(numThreads)</span><br><span class="line">  <span class="comment">/* a meter to track the average free capacity of the request handlers */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> aggregateIdleMeter = newMeter(requestHandlerAvgIdleMetricName, <span class="string">"percent"</span>, TimeUnit.NANOSECONDS)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"["</span> + logAndThreadNamePrefix + <span class="string">" Kafka Request Handler on Broker "</span> + brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="keyword">val</span> runnables = new mutable.ArrayBuffer[KafkaRequestHandler](numThreads)</span><br><span class="line">  <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until numThreads) &#123;</span><br><span class="line">    <span class="comment">// 创建KafkaRequestHandler线程</span></span><br><span class="line">    createHandler(i)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def createHandler(id: <span class="built_in">Int</span>): <span class="built_in">Unit</span> = synchronized &#123;</span><br><span class="line">    runnables += new KafkaRequestHandler(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)</span><br><span class="line">    KafkaThread.daemon(logAndThreadNamePrefix + <span class="string">"-kafka-request-handler-"</span> + id, runnables(id)).start()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="KafkaApis"><a href="#KafkaApis" class="headerlink" title="KafkaApis"></a>KafkaApis</h3><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">def handle(request: RequestChannel.Request) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    trace(s<span class="string">"Handling request:<span class="subst">$&#123;request.requestDesc(true)&#125;</span> from connection <span class="subst">$&#123;request.context.connectionId&#125;</span>;"</span> +</span><br><span class="line">      s<span class="string">"securityProtocol:<span class="subst">$&#123;request.context.securityProtocol&#125;</span>,principal:<span class="subst">$&#123;request.context.principal&#125;</span>"</span>)</span><br><span class="line">    request.header.apiKey match &#123;</span><br><span class="line">      case ApiKeys.PRODUCE =&gt; handleProduceRequest(request)</span><br><span class="line">      case ApiKeys.FETCH =&gt; handleFetchRequest(request)</span><br><span class="line">      case ApiKeys.LIST_OFFSETS =&gt; handleListOffsetRequest(request)</span><br><span class="line">      case ApiKeys.METADATA =&gt; handleTopicMetadataRequest(request)</span><br><span class="line">      case ApiKeys.LEADER_AND_ISR =&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">      case ApiKeys.STOP_REPLICA =&gt; handleStopReplicaRequest(request)</span><br><span class="line">      case ApiKeys.UPDATE_METADATA =&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">      case ApiKeys.CONTROLLED_SHUTDOWN =&gt; handleControlledShutdownRequest(request)</span><br><span class="line">      case ApiKeys.OFFSET_COMMIT =&gt; handleOffsetCommitRequest(request)</span><br><span class="line">      case ApiKeys.OFFSET_FETCH =&gt; handleOffsetFetchRequest(request)</span><br><span class="line">      case ApiKeys.FIND_COORDINATOR =&gt; handleFindCoordinatorRequest(request)</span><br><span class="line">      case ApiKeys.JOIN_GROUP =&gt; handleJoinGroupRequest(request)</span><br><span class="line">      case ApiKeys.HEARTBEAT =&gt; handleHeartbeatRequest(request)</span><br><span class="line">      case ApiKeys.LEAVE_GROUP =&gt; handleLeaveGroupRequest(request)</span><br><span class="line">      case ApiKeys.SYNC_GROUP =&gt; handleSyncGroupRequest(request)</span><br><span class="line">      case ApiKeys.DESCRIBE_GROUPS =&gt; handleDescribeGroupRequest(request)</span><br><span class="line">      case ApiKeys.LIST_GROUPS =&gt; handleListGroupsRequest(request)</span><br><span class="line">      case ApiKeys.SASL_HANDSHAKE =&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">      case ApiKeys.API_VERSIONS =&gt; handleApiVersionsRequest(request)</span><br><span class="line">      case ApiKeys.CREATE_TOPICS =&gt; handleCreateTopicsRequest(request)</span><br><span class="line">      case ApiKeys.DELETE_TOPICS =&gt; handleDeleteTopicsRequest(request)</span><br><span class="line">      case ApiKeys.DELETE_RECORDS =&gt; handleDeleteRecordsRequest(request)</span><br><span class="line">      case ApiKeys.INIT_PRODUCER_ID =&gt; handleInitProducerIdRequest(request)</span><br><span class="line">      case ApiKeys.OFFSET_FOR_LEADER_EPOCH =&gt; handleOffsetForLeaderEpochRequest(request)</span><br><span class="line">      case ApiKeys.ADD_PARTITIONS_TO_TXN =&gt; handleAddPartitionToTxnRequest(request)</span><br><span class="line">      case ApiKeys.ADD_OFFSETS_TO_TXN =&gt; handleAddOffsetsToTxnRequest(request)</span><br><span class="line">      case ApiKeys.END_TXN =&gt; handleEndTxnRequest(request)</span><br><span class="line">      case ApiKeys.WRITE_TXN_MARKERS =&gt; handleWriteTxnMarkersRequest(request)</span><br><span class="line">      case ApiKeys.TXN_OFFSET_COMMIT =&gt; handleTxnOffsetCommitRequest(request)</span><br><span class="line">      case ApiKeys.DESCRIBE_ACLS =&gt; handleDescribeAcls(request)</span><br><span class="line">      case ApiKeys.CREATE_ACLS =&gt; handleCreateAcls(request)</span><br><span class="line">      case ApiKeys.DELETE_ACLS =&gt; handleDeleteAcls(request)</span><br><span class="line">      case ApiKeys.ALTER_CONFIGS =&gt; handleAlterConfigsRequest(request)</span><br><span class="line">      case ApiKeys.DESCRIBE_CONFIGS =&gt; handleDescribeConfigsRequest(request)</span><br><span class="line">      case ApiKeys.ALTER_REPLICA_LOG_DIRS =&gt; handleAlterReplicaLogDirsRequest(request)</span><br><span class="line">      case ApiKeys.DESCRIBE_LOG_DIRS =&gt; handleDescribeLogDirsRequest(request)</span><br><span class="line">      case ApiKeys.SASL_AUTHENTICATE =&gt; handleSaslAuthenticateRequest(request)</span><br><span class="line">      case ApiKeys.CREATE_PARTITIONS =&gt; handleCreatePartitionsRequest(request)</span><br><span class="line">      case ApiKeys.CREATE_DELEGATION_TOKEN =&gt; handleCreateTokenRequest(request)</span><br><span class="line">      case ApiKeys.RENEW_DELEGATION_TOKEN =&gt; handleRenewTokenRequest(request)</span><br><span class="line">      case ApiKeys.EXPIRE_DELEGATION_TOKEN =&gt; handleExpireTokenRequest(request)</span><br><span class="line">      case ApiKeys.DESCRIBE_DELEGATION_TOKEN =&gt; handleDescribeTokensRequest(request)</span><br><span class="line">      case ApiKeys.DELETE_GROUPS =&gt; handleDeleteGroupsRequest(request)</span><br><span class="line">      case ApiKeys.ELECT_PREFERRED_LEADERS =&gt; handleElectPreferredReplicaLeader(request)</span><br><span class="line">      case ApiKeys.INCREMENTAL_ALTER_CONFIGS =&gt; handleIncrementalAlterConfigsRequest(request)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    case e: FatalExitError =&gt; <span class="keyword">throw</span> e</span><br><span class="line">    case e: Throwable =&gt; handleError(request, e)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    request.apiLocalCompleteTimeNanos = time.nanoseconds</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108092730192.png" alt="image-20191108092730192"></p>
<p>一个主题多个分区</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211105451796.png" alt="image-20191211105451796"></p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211105517601.png" alt="image-20191211105517601"></p>
<h3 id="增加主题"><a href="#增加主题" class="headerlink" title="增加主题"></a>增加主题</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br></pre></td></tr></table></figure>

<p>指定副本数和分区数，新增主题涉及的操作有分区、副本状态的转化、分区leader的分配、分区存储日志的创建</p>
<h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108151921837.png" alt="image-20191108151921837"></p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108152125545.png" alt="image-20191108152125545"></p>
<ol>
<li><p>每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p>
</li>
<li><p><strong>追随者副本是不对外提供服务</strong>的，它唯一的任务就是从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p>
</li>
<li><p><strong>当领导者副本挂掉了，或者说领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到</strong>，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老 Leader 副本重启回来后，只能作为追随者副本加入到集群中。</p>
</li>
</ol>
<h3 id="In-sync-Replicas（ISR）"><a href="#In-sync-Replicas（ISR）" class="headerlink" title="In-sync Replicas（ISR）"></a>In-sync Replicas（ISR）</h3><p>所有与leader同步的副本，包括leader</p>
<p><strong>如何算同步：</strong></p>
<p>Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒。这就是说，<strong>只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的</strong>，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p>
<h3 id="领导者选举"><a href="#领导者选举" class="headerlink" title="领导者选举"></a>领导者选举</h3><p>Kafka 把所有不在 ISR 中的存活副本都称为非同步副本。通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>
<p>默认不开启该设置</p>
<p>如何选举</p>
<p>kafka通过轮询算法保证副本是均匀分布在多个broker上</p>
<h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的连接，<strong>连接 bootstrap.servers 参数指定的所有 Broker</strong></p>
<p>Producer 每 5 分钟都会强制刷新一次元数据以保证它是最及时的数据</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191107221809350.png" alt="image-20191107221809350"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sender任务从RecordAccumulator取消息</span><br><span class="line">this.ioThread &#x3D; new KafkaThread(ioThreadName, this.sender, true);</span><br><span class="line">this.ioThread.start();</span><br></pre></td></tr></table></figure>



<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191107223940194.png" alt="image-20191107223940194"></p>
<h3 id="无丢失消息"><a href="#无丢失消息" class="headerlink" title="无丢失消息"></a>无丢失消息</h3><ol>
<li>不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。</li>
<li>设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>
<li>设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。</li>
<li>设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。</li>
<li>设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。</li>
<li>设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>
<li>确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。</li>
<li>确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。</li>
</ol>
<h3 id="消息重发"><a href="#消息重发" class="headerlink" title="消息重发"></a>消息重发</h3><p>最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。</p>
<p>至少一次（at least once）：消息不会丢失，但有可能被重复发送。</p>
<p>精确一次（exactly once）：消息不会丢失，也不会被重复发送。</p>
<p>倘若消息成功“提交”，但 Broker 的应答没有成功发送回 Producer 端（比如网络出现瞬时抖动），那么 Producer 就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是 Kafka 默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送</p>
<h4 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h4><p>去重重发消息设置。</p>
<p>指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即 props.put(“enable.idempotence”, ture)，或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。<strong>Kafka 自动帮你做消息的重复去重</strong>。</p>
<ol>
<li>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性</li>
<li>它只能实现单会话上的幂等性，不能实现跨会话的幂等性。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了</li>
</ol>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><ol>
<li>和幂等性 Producer 一样，开启 enable.idempotence = true。</li>
<li>设置 Producer 端参数 transactional. id。最好为其设置一个有意义的名字。<ol>
<li>read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。很显然，如果你用了事务型 Producer，那么对应的 Consumer 就不要使用这个值。</li>
<li>read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然了，它也能看到非事务型 Producer 写入的所有消息。</li>
</ol>
</li>
</ol>
<p>事务型 Producer 也不惧进程的重启。Producer 重启回来后，Kafka 依然保证它们发送消息的精确一次处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">producer.initTransactions();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">            producer.beginTransaction();</span><br><span class="line">            producer.send(record1);</span><br><span class="line">            producer.send(record2);</span><br><span class="line">            producer.commitTransaction();</span><br><span class="line">&#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">            producer.abortTransaction();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>事务能够保证跨分区、跨会话间的幂等性</p>
<h3 id="客户端生产者"><a href="#客户端生产者" class="headerlink" title="客户端生产者"></a>客户端生产者</h3><p>多线程单队列</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191212095641531.png" alt="image-20191212095641531"></p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191212135157447.png" alt="image-20191212135157447"></p>
<p>KafkaProducer实例化</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">KafkaProducer(Map&lt;String, Object&gt; configs,</span><br><span class="line">              Serializer&lt;K&gt; keySerializer,</span><br><span class="line">              Serializer&lt;V&gt; valueSerializer,</span><br><span class="line">              ProducerMetadata metadata,</span><br><span class="line">              KafkaClient kafkaClient,</span><br><span class="line">              ProducerInterceptors interceptors,</span><br><span class="line">              Time time) &#123;</span><br><span class="line">    ProducerConfig config = <span class="keyword">new</span> ProducerConfig(ProducerConfig.addSerializerToConfig(configs, keySerializer,</span><br><span class="line">            valueSerializer));</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Map&lt;String, Object&gt; userProvidedConfigs = config.originals();</span><br><span class="line">        <span class="keyword">this</span>.producerConfig = config;</span><br><span class="line">        <span class="keyword">this</span>.time = time;</span><br><span class="line">        String clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);</span><br><span class="line">        <span class="keyword">if</span> (clientId.length() &lt;= <span class="number">0</span>)</span><br><span class="line">            clientId = <span class="string">"producer-"</span> + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();</span><br><span class="line">        <span class="keyword">this</span>.clientId = clientId;</span><br><span class="line"></span><br><span class="line">        String transactionalId = userProvidedConfigs.containsKey(ProducerConfig.TRANSACTIONAL_ID_CONFIG) ?</span><br><span class="line">                (String) userProvidedConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG) : <span class="keyword">null</span>;</span><br><span class="line">        LogContext logContext;</span><br><span class="line">        <span class="keyword">if</span> (transactionalId == <span class="keyword">null</span>)</span><br><span class="line">            logContext = <span class="keyword">new</span> LogContext(String.format(<span class="string">"[Producer clientId=%s] "</span>, clientId));</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            logContext = <span class="keyword">new</span> LogContext(String.format(<span class="string">"[Producer clientId=%s, transactionalId=%s] "</span>, clientId, transactionalId));</span><br><span class="line">        log = logContext.logger(KafkaProducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        log.trace(<span class="string">"Starting the Kafka producer"</span>);</span><br><span class="line"></span><br><span class="line">        Map&lt;String, String&gt; metricTags = Collections.singletonMap(<span class="string">"client-id"</span>, clientId);</span><br><span class="line">        MetricConfig metricConfig = <span class="keyword">new</span> MetricConfig().samples(config.getInt(ProducerConfig.METRICS_NUM_SAMPLES_CONFIG))</span><br><span class="line">                .timeWindow(config.getLong(ProducerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS)</span><br><span class="line">                .recordLevel(Sensor.RecordingLevel.forName(config.getString(ProducerConfig.METRICS_RECORDING_LEVEL_CONFIG)))</span><br><span class="line">                .tags(metricTags);</span><br><span class="line">        List&lt;MetricsReporter&gt; reporters = config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG,</span><br><span class="line">                MetricsReporter<span class="class">.<span class="keyword">class</span>,</span></span><br><span class="line"><span class="class">                <span class="title">Collections</span>.<span class="title">singletonMap</span>(<span class="title">ProducerConfig</span>.<span class="title">CLIENT_ID_CONFIG</span>, <span class="title">clientId</span>))</span>;</span><br><span class="line">        reporters.add(<span class="keyword">new</span> JmxReporter(JMX_PREFIX));</span><br><span class="line">        <span class="keyword">this</span>.metrics = <span class="keyword">new</span> Metrics(metricConfig, reporters, time);</span><br><span class="line">        <span class="keyword">this</span>.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="keyword">long</span> retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);</span><br><span class="line">        <span class="keyword">if</span> (keySerializer == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,</span><br><span class="line">                                                                                     Serializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="keyword">this</span>.keySerializer.configure(config.originals(), <span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">            <span class="keyword">this</span>.keySerializer = keySerializer;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (valueSerializer == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,</span><br><span class="line">                                                                                       Serializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer.configure(config.originals(), <span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer = valueSerializer;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// load interceptors and make sure they get clientId</span></span><br><span class="line">        userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);</span><br><span class="line">        ProducerConfig configWithClientId = <span class="keyword">new</span> ProducerConfig(userProvidedConfigs, <span class="keyword">false</span>);</span><br><span class="line">        List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) configWithClientId.getConfiguredInstances(</span><br><span class="line">                ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptor<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors = interceptors;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">this</span>.interceptors = <span class="keyword">new</span> ProducerInterceptors&lt;&gt;(interceptorList);</span><br><span class="line">        ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keySerializer,</span><br><span class="line">                valueSerializer, interceptorList, reporters);</span><br><span class="line">        <span class="keyword">this</span>.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);</span><br><span class="line">        <span class="keyword">this</span>.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);</span><br><span class="line">        <span class="keyword">this</span>.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG);</span><br><span class="line">        <span class="keyword">this</span>.transactionManager = configureTransactionState(config, logContext, log);</span><br><span class="line">        <span class="keyword">int</span> deliveryTimeoutMs = configureDeliveryTimeout(config, log);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.apiVersions = <span class="keyword">new</span> ApiVersions();</span><br><span class="line">        <span class="keyword">this</span>.accumulator = <span class="keyword">new</span> RecordAccumulator(logContext,</span><br><span class="line">                config.getInt(ProducerConfig.BATCH_SIZE_CONFIG),</span><br><span class="line">                <span class="keyword">this</span>.compressionType,</span><br><span class="line">                lingerMs(config),</span><br><span class="line">                retryBackoffMs,</span><br><span class="line">                deliveryTimeoutMs,</span><br><span class="line">                metrics,</span><br><span class="line">                PRODUCER_METRIC_GROUP_NAME,</span><br><span class="line">                time,</span><br><span class="line">                apiVersions,</span><br><span class="line">                transactionManager,</span><br><span class="line">                <span class="keyword">new</span> BufferPool(<span class="keyword">this</span>.totalMemorySize, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), metrics, time, PRODUCER_METRIC_GROUP_NAME));</span><br><span class="line">        List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(</span><br><span class="line">                config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG),</span><br><span class="line">                config.getString(ProducerConfig.CLIENT_DNS_LOOKUP_CONFIG));</span><br><span class="line">        <span class="keyword">if</span> (metadata != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.metadata = metadata;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.metadata = <span class="keyword">new</span> ProducerMetadata(retryBackoffMs,</span><br><span class="line">                    config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG),</span><br><span class="line">                    logContext,</span><br><span class="line">                    clusterResourceListeners,</span><br><span class="line">                    Time.SYSTEM);</span><br><span class="line">          	<span class="comment">// 初始化了bootstrap地址</span></span><br><span class="line">            <span class="keyword">this</span>.metadata.bootstrap(addresses, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.errors = <span class="keyword">this</span>.metrics.sensor(<span class="string">"errors"</span>);</span><br><span class="line">        <span class="keyword">this</span>.sender = newSender(logContext, kafkaClient, <span class="keyword">this</span>.metadata);</span><br><span class="line">        String ioThreadName = NETWORK_THREAD_PREFIX + <span class="string">" | "</span> + clientId;</span><br><span class="line">        <span class="keyword">this</span>.ioThread = <span class="keyword">new</span> KafkaThread(ioThreadName, <span class="keyword">this</span>.sender, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.ioThread.start();</span><br><span class="line">        config.logUnused();</span><br><span class="line">        AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics, time.milliseconds());</span><br><span class="line">        log.debug(<span class="string">"Kafka producer started"</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="comment">// call close methods if internal objects are already constructed this is to prevent resource leak. see KAFKA-2121</span></span><br><span class="line">        close(Duration.ofMillis(<span class="number">0</span>), <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// now propagate the exception</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Failed to construct kafka producer"</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h4><p>org.apache.kafka.clients.producer.KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">     TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">         throwIfProducerClosed();</span><br><span class="line">         <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">         ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">         <span class="keyword">try</span> &#123;</span><br><span class="line">           	<span class="comment">// 获取topic的meta信息，如果没有，则需要发送获取meta请求</span></span><br><span class="line">             clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">         &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">             <span class="keyword">if</span> (metadata.isClosed())</span><br><span class="line">                 <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>, e);</span><br><span class="line">             <span class="keyword">throw</span> e;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">         Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">         <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">         <span class="keyword">try</span> &#123;</span><br><span class="line">             serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">         &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">             <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</span><br><span class="line">                     <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                     <span class="string">" specified in key.serializer"</span>, cce);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">         <span class="keyword">try</span> &#123;</span><br><span class="line">             serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">         &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">             <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</span><br><span class="line">                     <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                     <span class="string">" specified in value.serializer"</span>, cce);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">         tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line"></span><br><span class="line">         setReadOnly(record.headers());</span><br><span class="line">         Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line">         <span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                 compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">         ensureValidRecordSize(serializedSize);</span><br><span class="line">         <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">         log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</span><br><span class="line">         <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">         Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">             transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line"></span><br><span class="line">       	<span class="comment">// 将请求放入RecordAccumulator，队列的封装</span></span><br><span class="line">         RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                 serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">         <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">             log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">             <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> result.future;</span><br><span class="line">         <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">         <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">         <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">     &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">       ...</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// We keep track of the number of appending thread to make sure we do not miss batches in</span></span><br><span class="line">    <span class="comment">// abortIncompleteBatches().</span></span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    ByteBuffer buffer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (headers == <span class="keyword">null</span>) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// check if we have an in-progress batch</span></span><br><span class="line">      	<span class="comment">// 找到分区对应的消息队列</span></span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// we don't have an in-progress record batch try to allocate a new batch</span></span><br><span class="line">        <span class="keyword">byte</span> maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">        <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">        log.trace(<span class="string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());</span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line"></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...</span></span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            ProducerBatch batch = <span class="keyword">new</span> ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Don't deallocate this buffer in the finally block as it's being used in the record batch</span></span><br><span class="line">            buffer = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (buffer != <span class="keyword">null</span>)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RecordAccumulator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Logger log;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger flushesInProgress;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger appendsInProgress;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> batchSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CompressionType compression;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> lingerMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> retryBackoffMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> deliveryTimeoutMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BufferPool free;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Time time;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ApiVersions apiVersions;</span><br><span class="line">  	<span class="comment">// 一个分区一个消息队列</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; batches;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IncompleteBatches incomplete;</span><br><span class="line">    <span class="comment">// The following variables are only accessed by the sender thread, so we don't need to protect them.</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, Long&gt; muted;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> drainIndex;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TransactionManager transactionManager;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> nextBatchExpiryTimeMs = Long.MAX_VALUE; <span class="comment">// the earliest time (absolute) a batch will expire.</span></span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ClusterAndWaitTime <span class="title">waitOnMetadata</span><span class="params">(String topic, Integer partition, <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// add topic to metadata topic list if it is not there already and reset expiry</span></span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cluster.invalidTopics().contains(topic))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InvalidTopicException(topic);</span><br><span class="line"></span><br><span class="line">    metadata.add(topic);</span><br><span class="line"></span><br><span class="line">    Integer partitionsCount = cluster.partitionCountForTopic(topic);</span><br><span class="line">    <span class="comment">// Return cached metadata if we have it, and if the record's partition is either undefined</span></span><br><span class="line">    <span class="comment">// or within the known partition range</span></span><br><span class="line">    <span class="keyword">if</span> (partitionsCount != <span class="keyword">null</span> &amp;&amp; (partition == <span class="keyword">null</span> || partition &lt; partitionsCount))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> begin = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</span><br><span class="line">    <span class="keyword">long</span> elapsed;</span><br><span class="line">    <span class="comment">// Issue metadata requests until we have metadata for the topic and the requested partition,</span></span><br><span class="line">    <span class="comment">// or until maxWaitTimeMs is exceeded. This is necessary in case the metadata</span></span><br><span class="line">    <span class="comment">// is stale and the number of partitions for this topic has increased in the meantime.</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (partition != <span class="keyword">null</span>) &#123;</span><br><span class="line">            log.trace(<span class="string">"Requesting metadata update for partition &#123;&#125; of topic &#123;&#125;."</span>, partition, topic);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.trace(<span class="string">"Requesting metadata update for topic &#123;&#125;."</span>, topic);</span><br><span class="line">        &#125;</span><br><span class="line">        metadata.add(topic);</span><br><span class="line">      	<span class="comment">// 设置更新标记</span></span><br><span class="line">        <span class="keyword">int</span> version = metadata.requestUpdate();</span><br><span class="line">      	<span class="comment">// 唤醒sender线程</span></span><br><span class="line">        sender.wakeup();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">        		<span class="comment">// 等待meta更新完成  	</span></span><br><span class="line">            metadata.awaitUpdate(version, remainingWaitMs);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (TimeoutException ex) &#123;</span><br><span class="line">            <span class="comment">// Rethrow with original maxWaitMs to prevent logging exception with remainingWaitMs</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(</span><br><span class="line">                    String.format(<span class="string">"Topic %s not present in metadata after %d ms."</span>,</span><br><span class="line">                            topic, maxWaitMs));</span><br><span class="line">        &#125;</span><br><span class="line">        cluster = metadata.fetch();</span><br><span class="line">        elapsed = time.milliseconds() - begin;</span><br><span class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(partitionsCount == <span class="keyword">null</span> ?</span><br><span class="line">                    String.format(<span class="string">"Topic %s not present in metadata after %d ms."</span>,</span><br><span class="line">                            topic, maxWaitMs) :</span><br><span class="line">                    String.format(<span class="string">"Partition %d of topic %s with partition count %d is not present in metadata after %d ms."</span>,</span><br><span class="line">                            partition, topic, partitionsCount, maxWaitMs));</span><br><span class="line">        &#125;</span><br><span class="line">        metadata.maybeThrowException();</span><br><span class="line">        remainingWaitMs = maxWaitMs - elapsed;</span><br><span class="line">        partitionsCount = cluster.partitionCountForTopic(topic);</span><br><span class="line">      	<span class="comment">// do while，死循环直到获取到partitions</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (partitionsCount == <span class="keyword">null</span> || (partition != <span class="keyword">null</span> &amp;&amp; partition &gt;= partitionsCount));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, elapsed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">awaitUpdate</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> lastVersion, <span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">       <span class="keyword">long</span> currentTimeMs = time.milliseconds();</span><br><span class="line">       <span class="keyword">long</span> deadlineMs = currentTimeMs + timeoutMs &lt; <span class="number">0</span> ? Long.MAX_VALUE : currentTimeMs + timeoutMs;</span><br><span class="line">       time.waitObject(<span class="keyword">this</span>, () -&gt; &#123;</span><br><span class="line">           maybeThrowException();</span><br><span class="line">           <span class="keyword">return</span> updateVersion() &gt; lastVersion || isClosed();</span><br><span class="line">       &#125;, deadlineMs);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> (isClosed())</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Requested metadata update after close"</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="sender线程"><a href="#sender线程" class="headerlink" title="sender线程"></a>sender线程</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.apache.kafka.clients.producer.internals.Sender#run</span><br><span class="line">org.apache.kafka.clients.producer.internals.Sender#runOnce</span><br><span class="line">org.apache.kafka.clients.NetworkClient#poll</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOnce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (transactionManager.shouldResetProducerStateAfterResolvingSequences())</span><br><span class="line">                <span class="comment">// Check if the previous run expired batches which requires a reset of the producer state.</span></span><br><span class="line">                transactionManager.resetProducerId();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!transactionManager.isTransactional()) &#123;</span><br><span class="line">                <span class="comment">// this is an idempotent producer, so make sure we have a producer id</span></span><br><span class="line">                maybeWaitForProducerId();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionManager.hasUnresolvedSequences() &amp;&amp; !transactionManager.hasFatalError()) &#123;</span><br><span class="line">                transactionManager.transitionToFatalError(</span><br><span class="line">                    <span class="keyword">new</span> KafkaException(<span class="string">"The client hasn't received acknowledgment for "</span> +</span><br><span class="line">                        <span class="string">"some previously sent messages and can no longer retry them. It isn't safe to continue."</span>));</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionManager.hasInFlightTransactionalRequest() || maybeSendTransactionalRequest()) &#123;</span><br><span class="line">                <span class="comment">// as long as there are outstanding transactional requests, we simply wait for them to return</span></span><br><span class="line">                client.poll(retryBackoffMs, time.milliseconds());</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// do not continue sending if the transaction manager is in a failed state or if there</span></span><br><span class="line">            <span class="comment">// is no producer id (for the idempotent case).</span></span><br><span class="line">            <span class="keyword">if</span> (transactionManager.hasFatalError() || !transactionManager.hasProducerId()) &#123;</span><br><span class="line">                RuntimeException lastError = transactionManager.lastError();</span><br><span class="line">                <span class="keyword">if</span> (lastError != <span class="keyword">null</span>)</span><br><span class="line">                    maybeAbortBatches(lastError);</span><br><span class="line">                client.poll(retryBackoffMs, time.milliseconds());</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionManager.hasAbortableError()) &#123;</span><br><span class="line">                accumulator.abortUndrainedBatches(transactionManager.lastError());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AuthenticationException e) &#123;</span><br><span class="line">            <span class="comment">// This is already logged as error, but propagated here to perform any clean ups.</span></span><br><span class="line">            log.trace(<span class="string">"Authentication exception while processing transactional request: &#123;&#125;"</span>, e);</span><br><span class="line">            transactionManager.authenticationFailed(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> currentTimeMs = time.milliseconds();</span><br><span class="line">  	<span class="comment">// 从accumulator拿出将要发送的数据，并发送client.send</span></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = sendProducerData(currentTimeMs);</span><br><span class="line">    client.poll(pollTimeout, currentTimeMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">sendProducerData</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line">    <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if there are any partitions whose leaders are not known yet, force metadata update</span></span><br><span class="line">    <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// The set of topics with unknown leader contains topics with leader election pending as well as</span></span><br><span class="line">        <span class="comment">// topics which may have expired. Add the topic again to metadata to ensure it is included</span></span><br><span class="line">        <span class="comment">// and request metadata update, since there are messages to send to the topic.</span></span><br><span class="line">        <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">            <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line"></span><br><span class="line">        log.debug(<span class="string">"Requesting metadata update due to unknown leader topics from the batched records: &#123;&#125;"</span>,</span><br><span class="line">            result.unknownLeaderTopics);</span><br><span class="line">        <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// remove any nodes we aren't ready to send to</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Node node = iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.pollDelayMs(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create produce requests</span></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</span><br><span class="line">    addToInflightBatches(batches);</span><br><span class="line">    <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">        <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (ProducerBatch batch : batchList)</span><br><span class="line">                <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    accumulator.resetNextBatchExpiryTime();</span><br><span class="line">    List&lt;ProducerBatch&gt; expiredInflightBatches = getExpiredInflightBatches(now);</span><br><span class="line">    List&lt;ProducerBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.expiredBatches(now);</span><br><span class="line">    expiredBatches.addAll(expiredInflightBatches);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics</span></span><br><span class="line">    <span class="comment">// for expired batches. see the documentation of @TransactionState.resetProducerId to understand why</span></span><br><span class="line">    <span class="comment">// we need to reset the producer id here.</span></span><br><span class="line">    <span class="keyword">if</span> (!expiredBatches.isEmpty())</span><br><span class="line">        log.trace(<span class="string">"Expired &#123;&#125; batches in accumulator"</span>, expiredBatches.size());</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch expiredBatch : expiredBatches) &#123;</span><br><span class="line">        String errorMessage = <span class="string">"Expiring "</span> + expiredBatch.recordCount + <span class="string">" record(s) for "</span> + expiredBatch.topicPartition</span><br><span class="line">            + <span class="string">":"</span> + (now - expiredBatch.createdMs) + <span class="string">" ms has passed since batch creation"</span>;</span><br><span class="line">        failBatch(expiredBatch, -<span class="number">1</span>, NO_TIMESTAMP, <span class="keyword">new</span> TimeoutException(errorMessage), <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; expiredBatch.inRetry()) &#123;</span><br><span class="line">            <span class="comment">// This ensures that no new batches are drained until the current in flight batches are fully resolved.</span></span><br><span class="line">            transactionManager.markSequenceUnresolved(expiredBatch.topicPartition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sensors.updateProduceRequestMetrics(batches);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately</span></span><br><span class="line">    <span class="comment">// loop and try sending more data. Otherwise, the timeout will be the smaller value between next batch expiry</span></span><br><span class="line">    <span class="comment">// time, and the delay time for checking data availability. Note that the nodes may have data that isn't yet</span></span><br><span class="line">    <span class="comment">// sendable due to lingering, backing off, etc. This specifically does not include nodes with sendable data</span></span><br><span class="line">    <span class="comment">// that aren't ready to send since they would cause busy looping.</span></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">    pollTimeout = Math.min(pollTimeout, <span class="keyword">this</span>.accumulator.nextExpiryTimeMs() - now);</span><br><span class="line">    pollTimeout = Math.max(pollTimeout, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">        log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</span><br><span class="line">        <span class="comment">// if some partitions are already ready to be sent, the select time would be 0;</span></span><br><span class="line">        <span class="comment">// otherwise if some partition already has some data accumulated but not ready yet,</span></span><br><span class="line">        <span class="comment">// the select time will be the time difference between now and its linger expiry time;</span></span><br><span class="line">        <span class="comment">// otherwise the select time will be the time difference between now and the metadata expiry time;</span></span><br><span class="line">        pollTimeout = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sendProduceRequests(batches, now);</span><br><span class="line">    <span class="keyword">return</span> pollTimeout;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;ProducerBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (batches.isEmpty())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, ProducerBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// find the minimum magic version used when creating the record sets</span></span><br><span class="line">    <span class="keyword">byte</span> minUsedMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        <span class="keyword">if</span> (batch.magic() &lt; minUsedMagic)</span><br><span class="line">            minUsedMagic = batch.magic();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;</span><br><span class="line">        MemoryRecords records = batch.records();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// down convert if necessary to the minimum magic used. In general, there can be a delay between the time</span></span><br><span class="line">        <span class="comment">// that the producer starts building the batch and the time that we send the request, and we may have</span></span><br><span class="line">        <span class="comment">// chosen the message format based on out-dated metadata. In the worst case, we optimistically chose to use</span></span><br><span class="line">        <span class="comment">// the new message format, but found that the broker didn't support it, so we need to down-convert on the</span></span><br><span class="line">        <span class="comment">// client before sending. This is intended to handle edge cases around cluster upgrades where brokers may</span></span><br><span class="line">        <span class="comment">// not all support the same message format version. For example, if a partition migrates from a broker</span></span><br><span class="line">        <span class="comment">// which is supporting the new magic version to one which doesn't, then we will need to convert.</span></span><br><span class="line">        <span class="keyword">if</span> (!records.hasMatchingMagic(minUsedMagic))</span><br><span class="line">            records = batch.records().downConvert(minUsedMagic, <span class="number">0</span>, time).records();</span><br><span class="line">        produceRecordsByPartition.put(tp, records);</span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    String transactionalId = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional()) &#123;</span><br><span class="line">        transactionalId = transactionManager.transactionalId();</span><br><span class="line">    &#125;</span><br><span class="line">    ProduceRequest.Builder requestBuilder = ProduceRequest.Builder.forMagic(minUsedMagic, acks, timeout,</span><br><span class="line">            produceRecordsByPartition, transactionalId);</span><br><span class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    String nodeId = Integer.toString(destination);</span><br><span class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>,</span><br><span class="line">            requestTimeoutMs, callback);</span><br><span class="line">  	<span class="comment">// 发送请求</span></span><br><span class="line">    client.send(clientRequest, now);</span><br><span class="line">    log.trace(<span class="string">"Sent produce request to &#123;&#125;: &#123;&#125;"</span>, nodeId, requestBuilder);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doSend</span><span class="params">(ClientRequest clientRequest, <span class="keyword">boolean</span> isInternalRequest, <span class="keyword">long</span> now, AbstractRequest request)</span> </span>&#123;</span><br><span class="line">    String destination = clientRequest.destination();</span><br><span class="line">    RequestHeader header = clientRequest.makeHeader(request.version());</span><br><span class="line">    <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">        <span class="keyword">int</span> latestClientVersion = clientRequest.apiKey().latestVersion();</span><br><span class="line">        <span class="keyword">if</span> (header.apiVersion() == latestClientVersion) &#123;</span><br><span class="line">            log.trace(<span class="string">"Sending &#123;&#125; &#123;&#125; with correlation id &#123;&#125; to node &#123;&#125;"</span>, clientRequest.apiKey(), request,</span><br><span class="line">                    clientRequest.correlationId(), destination);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.debug(<span class="string">"Using older server API v&#123;&#125; to send &#123;&#125; &#123;&#125; with correlation id &#123;&#125; to node &#123;&#125;"</span>,</span><br><span class="line">                    header.apiVersion(), clientRequest.apiKey(), request, clientRequest.correlationId(), destination);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    Send send = request.toSend(destination, header);</span><br><span class="line">    InFlightRequest inFlightRequest = <span class="keyword">new</span> InFlightRequest(</span><br><span class="line">            clientRequest,</span><br><span class="line">            header,</span><br><span class="line">            isInternalRequest,</span><br><span class="line">            request,</span><br><span class="line">            send,</span><br><span class="line">            now);</span><br><span class="line">    <span class="keyword">this</span>.inFlightRequests.add(inFlightRequest);</span><br><span class="line">  	<span class="comment">// 暂存在channel</span></span><br><span class="line">    selector.send(send);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(Send send)</span> </span>&#123;</span><br><span class="line">        String connectionId = send.destination();</span><br><span class="line">        KafkaChannel channel = openOrClosingChannelOrFail(connectionId);</span><br><span class="line">        <span class="keyword">if</span> (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">            <span class="comment">// ensure notification via `disconnected`, leave channel in the state in which closing was triggered</span></span><br><span class="line">            <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                channel.setSend(send);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="comment">// update the state for consistency, the channel will be discarded after `close`</span></span><br><span class="line">                channel.state(ChannelState.FAILED_SEND);</span><br><span class="line">                <span class="comment">// ensure notification via `disconnected` when `failedSends` are processed in the next poll</span></span><br><span class="line">                <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">                close(channel, CloseMode.DISCARD_NO_NOTIFY);</span><br><span class="line">                <span class="keyword">if</span> (!(e <span class="keyword">instanceof</span> CancelledKeyException)) &#123;</span><br><span class="line">                    log.error(<span class="string">"Unexpected exception during send, closing connection &#123;&#125; and rethrowing exception &#123;&#125;"</span>,</span><br><span class="line">                            connectionId, e);</span><br><span class="line">                    <span class="keyword">throw</span> e;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>









<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    ensureActive();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!abortedSends.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// If there are aborted sends because of unsupported version exceptions or disconnects,</span></span><br><span class="line">        <span class="comment">// handle them immediately without waiting for Selector#poll.</span></span><br><span class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        handleAbortedSends(responses);</span><br><span class="line">        completeResponses(responses);</span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 如果需要更新meta，则发送获取meta请求</span></span><br><span class="line">    <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        log.error(<span class="string">"Unexpected error during I/O"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process completed actions</span></span><br><span class="line">    <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</span><br><span class="line">    List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    handleCompletedSends(responses, updatedNow);</span><br><span class="line">    handleCompletedReceives(responses, updatedNow);</span><br><span class="line">    handleDisconnections(responses, updatedNow);</span><br><span class="line">    handleConnections();</span><br><span class="line">    handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">    handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">    completeResponses(responses);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// should we update our metadata?</span></span><br><span class="line">        <span class="keyword">long</span> timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);</span><br><span class="line">        <span class="keyword">long</span> waitForMetadataFetch = hasFetchInProgress() ? defaultRequestTimeoutMs : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (metadataTimeout &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> metadataTimeout;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Beware that the behavior of this method and the computation of timeouts for poll() are</span></span><br><span class="line">        <span class="comment">// highly dependent on the behavior of leastLoadedNode.</span></span><br><span class="line">        Node node = leastLoadedNode(now);</span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">            log.debug(<span class="string">"Give up sending metadata request since no node is available"</span>);</span><br><span class="line">            <span class="keyword">return</span> reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maybeUpdate(now, node);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now, Node node)</span> </span>&#123;</span><br><span class="line">        String nodeConnectionId = node.idString();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (canSendRequest(nodeConnectionId, now)) &#123;</span><br><span class="line">          	<span class="comment">// 已建立连接</span></span><br><span class="line">            Metadata.MetadataRequestAndVersion requestAndVersion = metadata.newMetadataRequestAndVersion();</span><br><span class="line">            <span class="keyword">this</span>.inProgressRequestVersion = requestAndVersion.requestVersion;</span><br><span class="line">            MetadataRequest.Builder metadataRequest = requestAndVersion.requestBuilder;</span><br><span class="line">            log.debug(<span class="string">"Sending metadata request &#123;&#125; to node &#123;&#125;"</span>, metadataRequest, node);</span><br><span class="line"> 						<span class="comment">// 发送meta请求，相当于生成者发送消息，最终调用selector.send</span></span><br><span class="line">            sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);</span><br><span class="line">            <span class="keyword">return</span> defaultRequestTimeoutMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If there's any connection establishment underway, wait until it completes. This prevents</span></span><br><span class="line">        <span class="comment">// the client from unnecessarily connecting to additional nodes while a previous connection</span></span><br><span class="line">        <span class="comment">// attempt has not been completed.</span></span><br><span class="line">        <span class="keyword">if</span> (isAnyNodeConnecting()) &#123;</span><br><span class="line">            <span class="comment">// Strictly the timeout we should return here is "connect timeout", but as we don't</span></span><br><span class="line">            <span class="comment">// have such application level configuration, using reconnect backoff instead.</span></span><br><span class="line">            <span class="keyword">return</span> reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (connectionStates.canConnect(nodeConnectionId, now)) &#123;</span><br><span class="line">            <span class="comment">// We don't have a connection to this node right now, make one</span></span><br><span class="line">            log.debug(<span class="string">"Initialize connection to node &#123;&#125; for sending metadata request"</span>, node);</span><br><span class="line">          	<span class="comment">// 如果还没有连接，则初始化连接</span></span><br><span class="line">            initiateConnect(node, now);</span><br><span class="line">            <span class="keyword">return</span> reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// connected, but can't send more OR connecting</span></span><br><span class="line">        <span class="comment">// In either case, we just need to wait for a network event to let us know the selected</span></span><br><span class="line">        <span class="comment">// connection might be usable again.</span></span><br><span class="line">        <span class="keyword">return</span> Long.MAX_VALUE;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initiateConnect</span><span class="params">(Node node, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">     String nodeConnectionId = node.idString();</span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">         connectionStates.connecting(nodeConnectionId, now, node.host(), clientDnsLookup);</span><br><span class="line">         InetAddress address = connectionStates.currentAddress(nodeConnectionId);</span><br><span class="line">         log.debug(<span class="string">"Initiating connection to node &#123;&#125; using address &#123;&#125;"</span>, node, address);</span><br><span class="line">         selector.connect(nodeConnectionId,</span><br><span class="line">                 <span class="keyword">new</span> InetSocketAddress(address, node.port()),</span><br><span class="line">                 <span class="keyword">this</span>.socketSendBuffer,</span><br><span class="line">                 <span class="keyword">this</span>.socketReceiveBuffer);</span><br><span class="line">     &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">         log.warn(<span class="string">"Error connecting to node &#123;&#125;"</span>, node, e);</span><br><span class="line">         <span class="comment">/* attempt failed, we'll try again after the backoff */</span></span><br><span class="line">         connectionStates.disconnected(nodeConnectionId, now);</span><br><span class="line">         <span class="comment">/* maybe the problem is our metadata, update it */</span></span><br><span class="line">         metadataUpdater.requestUpdate();</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(Send send)</span> </span>&#123;</span><br><span class="line">       String connectionId = send.destination();</span><br><span class="line">  			<span class="comment">// 拿到一个socketChannel</span></span><br><span class="line">       KafkaChannel channel = openOrClosingChannelOrFail(connectionId);</span><br><span class="line">       <span class="keyword">if</span> (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">           <span class="comment">// ensure notification via `disconnected`, leave channel in the state in which closing was triggered</span></span><br><span class="line">           <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">             	<span class="comment">// 设置请求到socketChannel</span></span><br><span class="line">               channel.setSend(send);</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               <span class="comment">// update the state for consistency, the channel will be discarded after `close`</span></span><br><span class="line">               channel.state(ChannelState.FAILED_SEND);</span><br><span class="line">               <span class="comment">// ensure notification via `disconnected` when `failedSends` are processed in the next poll</span></span><br><span class="line">               <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">               close(channel, CloseMode.DISCARD_NO_NOTIFY);</span><br><span class="line">               <span class="keyword">if</span> (!(e <span class="keyword">instanceof</span> CancelledKeyException)) &#123;</span><br><span class="line">                   log.error(<span class="string">"Unexpected exception during send, closing connection &#123;&#125; and rethrowing exception &#123;&#125;"</span>,</span><br><span class="line">                           connectionId, e);</span><br><span class="line">                   <span class="keyword">throw</span> e;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSend</span><span class="params">(Send send)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.send != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to begin a send operation with prior send operation still in progress, connection id is "</span> + id);</span><br><span class="line">    <span class="keyword">this</span>.send = send;</span><br><span class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"timeout should be &gt;= 0"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> madeReadProgressLastCall = madeReadProgressLastPoll;</span><br><span class="line">    clear();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> dataInBuffers = !keysWithBufferedRead.isEmpty();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (hasStagedReceives() || !immediatelyConnectedKeys.isEmpty() || (madeReadProgressLastCall &amp;&amp; dataInBuffers))</span><br><span class="line">        timeout = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!memoryPool.isOutOfMemory() &amp;&amp; outOfMemory) &#123;</span><br><span class="line">        <span class="comment">//we have recovered from memory pressure. unmute any channel not explicitly muted for other reasons</span></span><br><span class="line">        log.trace(<span class="string">"Broker no longer low on memory - unmuting incoming sockets"</span>);</span><br><span class="line">        <span class="keyword">for</span> (KafkaChannel channel : channels.values()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (channel.isInMutableState() &amp;&amp; !explicitlyMutedChannels.contains(channel)) &#123;</span><br><span class="line">                channel.maybeUnmute();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        outOfMemory = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* check ready keys */</span></span><br><span class="line">    <span class="keyword">long</span> startSelect = time.nanoseconds();</span><br><span class="line">    <span class="keyword">int</span> numReadyKeys = select(timeout);</span><br><span class="line">    <span class="keyword">long</span> endSelect = time.nanoseconds();</span><br><span class="line">    <span class="keyword">this</span>.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (numReadyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty() || dataInBuffers) &#123;</span><br><span class="line">        Set&lt;SelectionKey&gt; readyKeys = <span class="keyword">this</span>.nioSelector.selectedKeys();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Poll from channels that have buffered data (but nothing more from the underlying socket)</span></span><br><span class="line">        <span class="keyword">if</span> (dataInBuffers) &#123;</span><br><span class="line">            keysWithBufferedRead.removeAll(readyKeys); <span class="comment">//so no channel gets polled twice</span></span><br><span class="line">            Set&lt;SelectionKey&gt; toPoll = keysWithBufferedRead;</span><br><span class="line">            keysWithBufferedRead = <span class="keyword">new</span> HashSet&lt;&gt;(); <span class="comment">//poll() calls will repopulate if needed</span></span><br><span class="line">            pollSelectionKeys(toPoll, <span class="keyword">false</span>, endSelect);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Poll from channels where the underlying socket has more data</span></span><br><span class="line">        pollSelectionKeys(readyKeys, <span class="keyword">false</span>, endSelect);</span><br><span class="line">        <span class="comment">// Clear all selected keys so that they are included in the ready count for the next select</span></span><br><span class="line">        readyKeys.clear();</span><br><span class="line"></span><br><span class="line">        pollSelectionKeys(immediatelyConnectedKeys, <span class="keyword">true</span>, endSelect);</span><br><span class="line">        immediatelyConnectedKeys.clear();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        madeReadProgressLastPoll = <span class="keyword">true</span>; <span class="comment">//no work is also "progress"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> endIo = time.nanoseconds();</span><br><span class="line">    <span class="keyword">this</span>.sensors.ioTime.record(endIo - endSelect, time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Close channels that were delayed and are now ready to be closed</span></span><br><span class="line">    completeDelayedChannelClose(endIo);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// we use the time at the end of select to ensure that we don't close any connections that</span></span><br><span class="line">    <span class="comment">// have just been processed in pollSelectionKeys</span></span><br><span class="line">    maybeCloseOldestConnection(endSelect);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add to completedReceives after closing expired connections to avoid removing</span></span><br><span class="line">    <span class="comment">// channels with completed receives until all staged receives are completed.</span></span><br><span class="line">    addToCompletedReceives();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>request，response头部，首先是一个定长的，4字节的头，表示完整数据包的大小，用于分包、粘包处理</p>
<p>在InFlightRequests中，存放了所有发出去，但是response还没有回来的request。request发出去的时候，入队；response回来，就把相对应的request出队</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">InFlightRequests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxInFlightRequestsPerConnection;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Deque&lt;NetworkClient.InFlightRequest&gt;&gt; requests = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="comment">/** Thread safe total number of in flight requests. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger inFlightRequestCount = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<p>服务端，保持同一个连接请求的顺序性，每当一个channel上面接收到一个request，这个channel就会被mute，然后等response返回之后，才会再unmute。这样就保证了同1个连接上面，同时只会有1个请求被处理</p>
<h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>单线程</p>
<h3 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h3><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制</p>
<p>组内必然可以有多个消费者或消费者实例（Consumer Instance），它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）</p>
<p><strong>每个分区只能由同一个消费者组内的一个 Consumer 实例来消费</strong></p>
<p>服务器保存(topic, partition, consumer_group_id) – offset对应关系</p>
<h4 id="消费者入组"><a href="#消费者入组" class="headerlink" title="消费者入组"></a>消费者入组</h4><ol>
<li><p>对于每1个consumer group，Kafka集群为其从broker集群中选择一个broker作为其coordinator。因此，第1步就是找到这个coordinator</p>
</li>
<li><p>找到coordinator之后，发送JoinGroup请求</p>
<p>第一个发送 JoinGroup 请求的成员自动成为领导者</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191213094928449.png" alt="image-20191213094928449"></p>
</li>
<li><p>JoinGroup返回之后，发送SyncGroup，得到自己所分配到的partition</p>
</li>
</ol>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191213094951652.png" alt="image-20191213094951652"></p>
<p>为什么要在consumer中选一个leader出来，进行分配，而不是由coordinator直接分配呢？关于这个, Kafka的官方文档有详细的分析。其中一个重要原因是为了灵活性：如果让server分配，一旦需要新的分配策略，server集群要重新部署，这对于已经在线上运行的集群来说，代价是很大的；而让client分配，server集群就不需要重新部署了</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Timer timer, <span class="keyword">final</span> <span class="keyword">boolean</span> includeMetadataInTimeout)</span> </span>&#123;</span><br><span class="line">  	<span class="comment">// 确保单线程</span></span><br><span class="line">    acquireAndEnsureOpen();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptions.hasNoSubscriptionOrUserAssignment()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Consumer is not subscribed to any topics or assigned any partitions"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// poll for new data until the timeout expires</span></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            client.maybeTriggerWakeup();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (includeMetadataInTimeout) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!updateAssignmentMetadataIfNeeded(timer)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (!updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE))) &#123;</span><br><span class="line">                    log.warn(<span class="string">"Still waiting for metadata"</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollForFetches(timer);</span><br><span class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">                <span class="comment">// before returning the fetched records, we can send off the next round of fetches</span></span><br><span class="line">                <span class="comment">// and avoid block waiting for their responses to enable pipelining while the user</span></span><br><span class="line">                <span class="comment">// is handling the fetched records.</span></span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                <span class="comment">// <span class="doctag">NOTE:</span> since the consumed position has already been updated, we must not allow</span></span><br><span class="line">                <span class="comment">// wakeups or any other errors to be triggered prior to returning the fetched records.</span></span><br><span class="line">                <span class="keyword">if</span> (fetcher.sendFetches() &gt; <span class="number">0</span> || client.hasPendingRequests()) &#123;</span><br><span class="line">                    client.pollNoWakeup();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">this</span>.interceptors.onConsume(<span class="keyword">new</span> ConsumerRecords&lt;&gt;(records));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">while</span> (timer.notExpired());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="偏移量提交"><a href="#偏移量提交" class="headerlink" title="偏移量提交"></a>偏移量提交</h3><p>老版本 Consumer 的位移管理是依托于 Apache ZooKeeper，ZooKeeper 其实并不适用于这种高频的写操作。</p>
<p>新版本把位移保存在 Kafka Broker内部的主题中，主题名叫__consumer_offsets</p>
<p>从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交</p>
<h4 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records &#x3D;</span><br><span class="line">                        consumer.poll(Duration.ofSeconds(1));</span><br><span class="line">            process(records); &#x2F;&#x2F; 处理消息</span><br><span class="line">            try &#123;</span><br><span class="line">                        consumer.commitSync();</span><br><span class="line">            &#125; catch (CommitFailedException e) &#123;</span><br><span class="line">                        handle(e); &#x2F;&#x2F; 处理提交失败异常</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>没有重试机制</p>
<h4 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h4><p>设置enable.auto.commit为true</p>
<p>设置auto.commit.interval.ms，它的默认值是 5 秒，表明Kafka每5秒会为你自动提交一次位移。</p>
<p>poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息</p>
<p>调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果</p>
<p>有重复消费情况</p>
<p>结合两种提交策略：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                        ConsumerRecords&lt;String, String&gt; records = </span><br><span class="line">                                    consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">                        process(records); <span class="comment">// 处理消息</span></span><br><span class="line">                        commitAysnc(); <span class="comment">// 使用异步提交规避阻塞</span></span><br><span class="line">            &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">            handle(e); <span class="comment">// 处理异常</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                        consumer.commitSync(); <span class="comment">// 最后一次提交使用同步阻塞式提交</span></span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">       consumer.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="重平衡"><a href="#重平衡" class="headerlink" title="重平衡"></a>重平衡</h2><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区</p>
<ol>
<li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li>
<li>订阅主题数发生变更。Consumer Group 可以使用正则表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance。</li>
<li>订阅主题的分区数发生变更。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。</li>
</ol>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191108114145781.png" alt="image-20191108114145781"></p>
<p>在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。</p>
<h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><p>每个broker就是一个kafka的实例或者称之为kafka的服务。其实控制器也是一个broker，控制器也叫leader broker。</p>
<ol>
<li>主题管理（创建、删除、增加分区）</li>
<li>分区重分配</li>
<li>Preferred 领导者选举</li>
<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</li>
<li>数据服务</li>
</ol>
<h3 id="controller选举"><a href="#controller选举" class="headerlink" title="controller选举"></a>controller选举</h3><p>通过在zookeeper上创建临时节点的方式，选举为leader broker，即控制器</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211114800350.png" alt="image-20191211114800350"></p>
<h3 id="分区leader选举"><a href="#分区leader选举" class="headerlink" title="分区leader选举"></a>分区leader选举</h3><p>ar集合中第一个存活副本，且在isr集合中</p>
<h3 id="控制器故障转移（Failover）"><a href="#控制器故障转移（Failover）" class="headerlink" title="控制器故障转移（Failover）"></a>控制器故障转移（Failover）</h3><p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191210174046139.png" alt="image-20191210174046139"></p>
<p>最开始时，Broker 0 是控制器。当 Broker 0 宕机后，ZooKeeper 通过 Watch 机制感知到并删除了 /controller 临时节点。之后，所有存活的 Broker 开始竞选新的控制器身份。Broker 3 最终赢得了选举，成功地在 ZooKeeper 上重建了 /controller 节点。之后，Broker 3 会从 ZooKeeper 中读取集群元数据信息，并初始化到自己的缓存中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">elect</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">    activeControllerId = zkClient.getControllerId.getOrElse(-<span class="number">1</span>)</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * We can get here during the initial startup and the handleDeleted ZK callback. Because of the potential race condition,</span></span><br><span class="line"><span class="comment">     * it's possible that the controller has already been elected when we get here. This check will prevent the following</span></span><br><span class="line"><span class="comment">     * createEphemeralPath method from getting into an infinite loop if this broker is already the controller.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (activeControllerId != -<span class="number">1</span>) &#123;</span><br><span class="line">      debug(s<span class="string">"Broker $activeControllerId has been elected as the controller, so stopping the election process."</span>)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 如果没抛异常，则该实例选举成功，成为leader</span></span><br><span class="line">      val (epoch, epochZkVersion) = zkClient.registerControllerAndIncrementControllerEpoch(config.brokerId)</span><br><span class="line">      controllerContext.epoch = epoch</span><br><span class="line">      controllerContext.epochZkVersion = epochZkVersion</span><br><span class="line">      activeControllerId = config.brokerId</span><br><span class="line"></span><br><span class="line">      info(s<span class="string">"$&#123;config.brokerId&#125; successfully elected as the controller. Epoch incremented to $&#123;controllerContext.epoch&#125; "</span> +</span><br><span class="line">        s<span class="string">"and epoch zk version is now $&#123;controllerContext.epochZkVersion&#125;"</span>)</span><br><span class="line"></span><br><span class="line">      onControllerFailover()</span><br><span class="line">    &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191210181215208.png" alt="image-20191210181215208"></p>
<p>在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息。消费者只能消费已提交消息</p>
<p>高水位和 LEO 是副本对象的两个重要属性。Kafka 所有副本都有对应的高水位和 LEO 值，而不仅仅是 Leader 副本。只不过 Leader 副本比较特殊，Kafka 使用 Leader 副本的高水位来定义所在分区的高水位。换句话说，分区的高水位就是其 Leader 副本的高水位。</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211093647072.png" alt="image-20191211093647072"></p>
<p>Broker 0 上保存了某分区的 Leader 副本和所有 Follower 副本的 LEO 值，而 Broker 1 上仅仅保存了该分区的某个 Follower 副本</p>
<h4 id="处理生产者请求的逻辑如下："><a href="#处理生产者请求的逻辑如下：" class="headerlink" title="处理生产者请求的逻辑如下："></a>处理生产者请求的逻辑如下：</h4><ol>
<li><p>写入消息到本地磁盘。</p>
</li>
<li><p>更新分区高水位值。</p>
</li>
</ol>
<p>​    i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p>
<p>​    ii. 获取 Leader 副本高水位值：currentHW。iii. 更新 currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}。</p>
<h4 id="处理-Follower-副本拉取消息的逻辑如下："><a href="#处理-Follower-副本拉取消息的逻辑如下：" class="headerlink" title="处理 Follower 副本拉取消息的逻辑如下："></a>处理 Follower 副本拉取消息的逻辑如下：</h4><ol>
<li><p>读取磁盘（或页缓存）中的消息数据。</p>
</li>
<li><p>使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p>
</li>
<li><p>更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p>
</li>
</ol>
<h4 id="从-Leader-拉取消息的处理逻辑如下："><a href="#从-Leader-拉取消息的处理逻辑如下：" class="headerlink" title="从 Leader 拉取消息的处理逻辑如下："></a>从 Leader 拉取消息的处理逻辑如下：</h4><ol>
<li><p>写入消息到本地磁盘。</p>
</li>
<li><p>更新 LEO 值。更新高水位值。</p>
<p>i. 获取 Leader 发送的高水位值：currentHW。</p>
<p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p>
<p>iii. 更新高水位为 min(currentHW, currentLEO)。</p>
</li>
</ol>
<p>所有 Broker 都有各自的 Coordinator 组件，专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。</p>
<p>Kafka 为某个Consumer Group确定Coordinator 所在的 Broker 的算法有 2 个步骤。</p>
<p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。</p>
<p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p>
<p>第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。</p>
<p>第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。</p>
<p>第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。</p>
<p>最后，客户端程序只能与分区的领导者副本进行交互。</p>
<p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191025140100157.png" alt="image-20191025140100157"></p>
<h2 id="协调器"><a href="#协调器" class="headerlink" title="协调器"></a>协调器</h2><ol>
<li>消费者协调器（ConsumerCoordinator）</li>
<li>组协调器（GroupCoordinator）</li>
<li>任务管理协调器（WorkCoordinator）</li>
</ol>
<h2 id="rocketMQ"><a href="#rocketMQ" class="headerlink" title="rocketMQ"></a>rocketMQ</h2><h3 id="namesrv-VS-zk"><a href="#namesrv-VS-zk" class="headerlink" title="namesrv VS zk"></a>namesrv VS zk</h3><p>  1、我们可以对比下kafka和rocketMq在协调节点选择上的差异，kafka通过zookeeper来进行协调，而rocketMq通过自身的namesrv进行协调。</p>
<p>  2、kafka在具备选举功能，在Kafka里面，Master/Slave的选举，有2步：第1步，先通过ZK在所有机器中，选举出一个KafkaController；第2步，再由这个Controller，决定每个partition的Master是谁，Slave是谁。因为有了选举功能，所以kafka某个partition的master挂了，该partition对应的某个slave会升级为主对外提供服务。</p>
<p>  3、rocketMQ不具备选举，Master/Slave的角色也是固定的。当一个Master挂了之后，你可以写到其他Master上，但不能让一个Slave切换成Master。那么rocketMq是如何实现高可用的呢，其实很简单，rocketMq的所有broker节点的角色都是一样，上面分配的topic和对应的queue的数量也是一样的，Mq只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他broker上面，而并不是这个broker对应的slave升级为主。</p>
<p> 4、rocketMq在协调节点的设计上显得更加轻量，用了另外一种方式解决高可用的问题，思路也是可以借鉴的。</p>
<h3 id="消息存储"><a href="#消息存储" class="headerlink" title="消息存储"></a>消息存储</h3><p><img src="https://github.com/garydai/garydai.github.com/raw/master/_posts/pic/image-20191211173947135.png" alt="image-20191211173947135"></p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p><a href="https://time.geekbang.org/column/article/105112" target="_blank" rel="noopener">https://time.geekbang.org/column/article/105112</a></p>
<p><a href="https://www.jianshu.com/p/a6b9e5342878" target="_blank" rel="noopener">https://www.jianshu.com/p/a6b9e5342878</a></p>
<p><a href="https://www.jianshu.com/p/c474ca9f9430" target="_blank" rel="noopener">https://www.jianshu.com/p/c474ca9f9430</a></p>
<p><a href="https://matt33.com/2017/07/08/kafka-producer-metadata/" target="_blank" rel="noopener">https://matt33.com/2017/07/08/kafka-producer-metadata/</a></p>
<p><a href="https://blog.csdn.net/chunlongyu/article/details/52651960" target="_blank" rel="noopener">https://blog.csdn.net/chunlongyu/article/details/52651960</a></p>

    
  </div>

</article>


   

   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2019/04/28/2019-4-28-redis/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2019/05/29/2019-5-29-ssh/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">Close</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-default">
    

    

    
    

    

    
    

    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
